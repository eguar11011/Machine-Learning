{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import graphviz as gv\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1.0/(1.0 + np.exp(-x))\n",
    "\n",
    "def relu(x):\n",
    "    return max(0, x)\n",
    "\n",
    "def predict(w, x):\n",
    "    a = np.zeros((3,))\n",
    "    a[2] = relu(np.dot(x,w[6:8]) + w[8])\n",
    "\n",
    "    a[1] = relu(np.dot(x,w[3:5]) + w[5])\n",
    "\n",
    "    a[0] = sigmoid(np.dot(a[1:3], w[0:2]) + w[2])\n",
    "    return a[0]\n",
    "\n",
    "def create_neural_network_graph(X, Y, w):\n",
    "    nn_graph = gv.Digraph('NeuralNetwork')\n",
    "    \n",
    "    for i, x in enumerate(X):\n",
    "        nn_graph.node(f'input1_{i}', f'Input 1: {x[0]}', shape='circle')\n",
    "        nn_graph.node(f'input2_{i}', f'Input 2: {x[1]}', shape='circle')\n",
    "        \n",
    "        dot_product_1 = np.dot(x, w[3:5])\n",
    "        dot_product_2 = np.dot(x, w[6:8])\n",
    "\n",
    "        nn_graph.node(f'relu1_{i}', f'RELU 1: {relu(dot_product_1 + w[5])}\\nBias: {w[5]} \\nDot product: {dot_product_1}\\nWeights: {w[3:5]}', shape='rectangle')\n",
    "        nn_graph.node(f'relu2_{i}', f'RELU 2: {relu(dot_product_2 + w[8])}\\nBias: {w[8]}  \\nDot product: {dot_product_2}\\nWeights: {w[6:8]}', shape='rectangle')\n",
    "        \n",
    "        dot_product_3 = np.dot([relu(dot_product_1 + w[5]), relu(dot_product_2 + w[8])], w[0:2])\n",
    "\n",
    "        nn_graph.node(f'sigmoid_{i}', f'Sigmoid: {sigmoid(dot_product_3 + w[2])}\\nBias: {w[2]}  \\nDot product: {dot_product_3}\\nWeights: {w[0:2]}', shape='rectangle')\n",
    "        \n",
    "        nn_graph.node(f'output_{i}', f'Output: {predict(w, x)} (actual: {Y[i]})', shape='circle')\n",
    "\n",
    "        nn_graph.edges([(f'input1_{i}', f'relu1_{i}'), (f'input1_{i}', f'relu2_{i}'), (f'input2_{i}', f'relu1_{i}'), (f'input2_{i}', f'relu2_{i}')])\n",
    "        nn_graph.edges([(f'relu1_{i}', f'sigmoid_{i}'), (f'relu2_{i}', f'sigmoid_{i}')])\n",
    "        nn_graph.edge(f'sigmoid_{i}', f'output_{i}')\n",
    "\n",
    "    return nn_graph\n",
    "\n",
    "\n",
    "w = np.array([10,4, \n",
    "              -7, \n",
    "              2, 2.005, \n",
    "              -2,\n",
    "              -7.999, -8,\n",
    "              4])\n",
    "\n",
    "\n",
    "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
    "\n",
    "Y = np.array([1, 0, 0, 1])\n",
    "\n",
    "nn_graph = create_neural_network_graph(X, Y, w)\n",
    "\n",
    "#nn_graph.render('neural_network_data_flow_with_weights.gv', view=True)\n",
    "display(nn_graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import graphviz as gv\n",
    "\n",
    "def draw_network(w):\n",
    "    g = gv.Digraph(format='png')\n",
    "\n",
    "    # agregar nodos\n",
    "    g.node('x1', 'x1')\n",
    "    g.node('x2', 'x2')\n",
    "    g.node('h1', 'h1')\n",
    "    g.node('h2', 'h2')\n",
    "    g.node('y', 'y')\n",
    "\n",
    "    # agregar conexiones\n",
    "    g.edge('x1', 'h1', label=str(w[0]))\n",
    "    g.edge('x2', 'h1', label=str(w[1]))\n",
    "    g.edge('x1', 'h2', label=str(w[3]))\n",
    "    g.edge('x2', 'h2', label=str(w[4]))\n",
    "    g.edge('h1', 'y', label=str(w[2]))\n",
    "    g.edge('h2', 'y', label=str(w[6]))\n",
    "    # configurar el estilo del gráfico\n",
    "    g.attr(rankdir='LR', size='8,5')\n",
    "\n",
    "    # renderizar y mostrar el gráfico\n",
    "    display(g)\n",
    "\n",
    "# calcular las salidas para cada entrada\n",
    "outputs = [predict(w, x) for x in X]\n",
    "\n",
    "# dibujar el gráfico de la red neuronal\n",
    "draw_network(w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.\n",
    "Find a weight vector such that the neural network calculates the negated XOR function:\n",
    "    \n",
    "$$f(x,y)=\\neg(x\\text{ xor }y)$$\n",
    "\n",
    "Use the following function to test your answer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_prediction(X, Y, w):\n",
    "    epsilon = 0.001\n",
    "    for i, x in enumerate(X):\n",
    "        print (x, predict(w, x))\n",
    "        if np.abs(predict(w, x) - Y[i]) > epsilon: \n",
    "            print(np.abs(predict(w, x) - Y[i]))\n",
    "            raise Exception(\"Prediction error\")\n",
    "    return True\n",
    "test_prediction(X, Y, w)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.\n",
    "\n",
    "Suppose that we have a cross entropy loss function:\n",
    "\n",
    "$$L(w, x, y) = - y \\log f_w(x) - (1-y) \\log (1-f_w(x))$$\n",
    "\n",
    "where $f_w(x)$ corresponds to the prediction of the neural network from the  previous question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    return -y * np.log(predict(w, x)) -(1. - y) * np.log(1. - predict(w, x)) \n",
    "\n",
    "print([loss(w, X[i], Y[i]) for i in range(4)])\n",
    "print([predict(w,X[i]) -Y[i] for i in range(4)])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Write a function that calculates the gradient of the loss with respect to the weights:\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss(w, x, y):\n",
    "    return -y * np.log(x) -(1. - y) * np.log(1. - x) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backpropagation(w, x, y):\n",
    "    # Left\n",
    "    preac_0 = np.dot(x, w[3:5]) + w[5]\n",
    "    act_0 = relu(preac_0)\n",
    "    # Right\n",
    "    preac_1 = np.dot(x, w[6:8]) + w[8]\n",
    "    act_1 = relu(preac_1)\n",
    "    # predic\n",
    "    preac_2 = np.dot([act_0,act_1], w[0:2]) + w[2]\n",
    "    act_2 = sigmoid(preac_2)\n",
    "    # Gradientes\n",
    "    delta = np.zeros_like(w)    \n",
    "    #________________________________________________________\n",
    "  \n",
    "    \"\"\"\n",
    "    La derivada en general de w_0, w_1, w_2:\n",
    "    dL/dw_0 = (dL/dact_2) * (dact_2/dpreac_2) * (dpreact_2/dw_0)\n",
    "    dL/dw_1 = (dL/dact_2) * (dact_2/dpreac_2) * (dpreact_2/dw_1)\n",
    "    dL/dw_2 = (dL/dact_2) * (dact_2/dpreac_2) * (dpreact_2/dw_2)  \n",
    "\n",
    "    Veamos la función de perdida:\n",
    "    L(w, x, y) = - y \\log f_w(x) - (1-y) \\log (1-f_w(x))\n",
    "    dL/df_w(x) = -y/f_w(x) + 1-y/1-f_w(x)\n",
    "    Note qué; se genera un arbo de realizar la derivada interna de:        \n",
    "    dL_dfw_x_left = -y/f_w(x)\n",
    "    dL_dfw_x_right = (1 - y) / (1 - fw_x)  \n",
    "    \"\"\" \n",
    "\n",
    "    dL_dfw_x_left = -y / act_2\n",
    "    dL_dfw_x_right = (1 - y) / (1 - act_2)\n",
    "\n",
    "    dact_2_dpreac_2 =  act_2 *(1-act_2)\n",
    "\n",
    "    dpreac_2_dw_0 = act_0    # derivar -> act_0*w_0+act_1*w_1+w_2\n",
    "    dpreac_2_dw_1 = act_1\n",
    "    dpreac_2_dw_2 = 1\n",
    "    \n",
    "    delta[0] = (dL_dfw_x_left*dact_2_dpreac_2*dpreac_2_dw_0) + (dL_dfw_x_right*dact_2_dpreac_2*dpreac_2_dw_0)\n",
    "    delta[1] = (dL_dfw_x_left*dact_2_dpreac_2*dpreac_2_dw_1) + (dL_dfw_x_right*dact_2_dpreac_2*dpreac_2_dw_1)\n",
    "    delta[2] = (dL_dfw_x_left*dact_2_dpreac_2*dpreac_2_dw_2) + (dL_dfw_x_right*dact_2_dpreac_2*dpreac_2_dw_2)\n",
    "    \"\"\"\n",
    "    La derivada en general de w_3, w_4, w_5: \n",
    "    dL/dw_3 = (dL/dact_2 * dact_2/dpreac_2) * (dpreac_2/dact_0) * (dact_0/dpreac_0*dpreac_0/dw_3)\n",
    "    dL/dw_4 = (dL/dact_2 * dact_2/dpreac_2) * (dpreac_2/dact_0) * (dact_0/dpreac_0*dpreac_0/dw_4)\n",
    "    dL/dw_5 = (dL/dact_2 * dact_2/dpreac_2) * (dpreac_2/dact_0) * (dact_0/dpreac_0*dpreac_0/dw_5)\n",
    "    \"\"\"\n",
    "    dpreac_2_dact_0 = w[0] # derivar -> act_0*w_0+ act_1*w_1 +w_2\n",
    "    dact_0_dpreac_0 = int(preac_0>0) # derivada de Relu -> 1 si x>0\n",
    "\n",
    "    dpreac_0_dw_3 = x[0] # derivar -> Inp_0*w_3 + Inp_1*w_4 + w_5\n",
    "    dpreac_0_dw_4 = x[1]\n",
    "    dpreac_0_dw_5 = 1\n",
    "    \n",
    "    delta[3] = (dL_dfw_x_left*dact_2_dpreac_2) * (dpreac_2_dact_0) * (dact_0_dpreac_0*dpreac_0_dw_3)+(dL_dfw_x_right*dact_2_dpreac_2) * (dpreac_2_dact_0) * (dact_0_dpreac_0*dpreac_0_dw_3)\n",
    "    delta[4] = (dL_dfw_x_left*dact_2_dpreac_2) * (dpreac_2_dact_0) * (dact_0_dpreac_0*dpreac_0_dw_4)+(dL_dfw_x_right*dact_2_dpreac_2) * (dpreac_2_dact_0) * (dact_0_dpreac_0*dpreac_0_dw_4)\n",
    "    delta[5] = (dL_dfw_x_left*dact_2_dpreac_2) * (dpreac_2_dact_0) * (dact_0_dpreac_0*dpreac_0_dw_5)+(dL_dfw_x_right*dact_2_dpreac_2) * (dpreac_2_dact_0) * (dact_0_dpreac_0*dpreac_0_dw_5)\n",
    "\n",
    "\n",
    "    \"\"\"\n",
    "    La derivada en general de w_6, w_7, w_8: \n",
    "    dL/dw_6 = (dL/dact_2 * dact_2/dpreac_2) * (dpreac_2/dact_1) * (dact_1/dpreac_1*dpreac_1/dw_6)\n",
    "    dL/dw_7 = (dL/dact_2 * dact_2/dpreac_2) * (dpreac_2/dact_1) * (dact_1/dpreac_1*dpreac_1/dw_7)\n",
    "    dL/dw_8 = (dL/dact_2 * dact_2/dpreac_2) * (dpreac_2/dact_1) * (dact_1/dpreac_1*dpreac_1/dw_8)\n",
    "    \"\"\"\n",
    "    dpreac_2_dact_1 = w[1] # derivar -> act_0*w_0+ act_1*w_1 +w_2\n",
    "    dact_1_dpreac_1 = int(preac_1>0) # derivada de Relu -> 1 si x>0\n",
    "\n",
    "    dpreac_1_dw_6 = x[0] # derivar -> Inp_0*w_6 + Inp_1*w_7 + w_8\n",
    "    dpreac_1_dw_7 = x[1]\n",
    "    dpreac_1_dw_8 = 1\n",
    "\n",
    "    delta[6] = (dL_dfw_x_left*dact_2_dpreac_2) * (dpreac_2_dact_1) * (dact_1_dpreac_1*dpreac_1_dw_6)+(dL_dfw_x_right*dact_2_dpreac_2) * (dpreac_2_dact_1) * (dact_1_dpreac_1*dpreac_1_dw_6)\n",
    "    delta[7] = (dL_dfw_x_left*dact_2_dpreac_2) * (dpreac_2_dact_1) * (dact_1_dpreac_1*dpreac_1_dw_7)+(dL_dfw_x_right*dact_2_dpreac_2) * (dpreac_2_dact_1) * (dact_1_dpreac_1*dpreac_1_dw_7)\n",
    "    delta[8] = (dL_dfw_x_left*dact_2_dpreac_2) * (dpreac_2_dact_1) * (dact_1_dpreac_1*dpreac_1_dw_8)+(dL_dfw_x_right*dact_2_dpreac_2) * (dpreac_2_dact_1) * (dact_1_dpreac_1*dpreac_1_dw_8)\n",
    "\n",
    "    return delta\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "tws = np.array([[-0.70032787,  0.05195189,  0.02322052,  1.4555916 ,  0.12168937,\n",
    "        -0.93580307, -0.58649814, -0.25847014, -0.11531032],\n",
    "       [ 1.11732048,  0.60225913,  0.05929297, -1.09018787,  2.33186956,\n",
    "         0.68248461, -0.16774443, -0.12996126,  0.31700533],\n",
    "       [ 0.80285183,  0.08585098,  1.62153749,  0.61251705,  0.18263732,\n",
    "         2.08412764, -0.2940164 , -0.72975557, -1.33828478],\n",
    "       [-0.74973286,  1.24623671,  0.63761743,  2.13714693,  0.90258674,\n",
    "         1.70238408, -2.60308453,  0.03070776,  2.34519973]])\n",
    "txs = np.array([[-0.96460511,  0.79790901],\n",
    "       [ 0.34546505,  0.92062212],\n",
    "       [-0.85750439,  0.50268203],\n",
    "       [ 0.69988938,  2.07328522]])\n",
    "tys = np.array([[ 0.66453404],\n",
    "       [-1.35012527],\n",
    "       [-0.7976646 ],\n",
    "       [ 0.57095802]])\n",
    "tls = np.array([[ 0.        , -0.03798627, -0.1555583 ,  0.        ,  0.        ,\n",
    "         0.        ,  0.0077955 , -0.00644834, -0.00808155],\n",
    "       [ 5.63408329,  0.32024725,  2.29715661,  0.88669136,  2.36292409,\n",
    "         2.56666012,  0.47794521,  1.27366556,  1.38348354],\n",
    "       [ 2.8850554 ,  0.        ,  1.74777687, -1.20325518,  0.70536637,\n",
    "         1.40320586,  0.        ,  0.        ,  0.        ],\n",
    "       [-2.48486794, -0.2877231 , -0.49016324,  0.25720339,  0.76191466,\n",
    "         0.36749148, -0.42753402, -1.26648581, -0.61085942]])\n",
    "\n",
    "def test_dL_dw():\n",
    "    num_tests = tws.shape[0]\n",
    "    epsilon = 0.0001\n",
    "    for i in range(num_tests):\n",
    "        tw = tws[i]\n",
    "        tx = txs[i]\n",
    "        ty = tys[i]\n",
    "        tl = tls[i]\n",
    "        if   np.linalg.norm(backpropagation(tw, tx, ty) - tl)> epsilon:\n",
    "            raise Exception(\"dL_dw test failed!\")\n",
    "    return print(\"OK\")\n",
    "\n",
    "test_dL_dw()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
